{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataLoader, DataVisualizer, DatasetBuilder\n",
    "#from models import *\n",
    "import tensorflow as tf\n",
    "from utils.input import *\n",
    "\n",
    "def input_pipeline(path:str='DATA/speech_commands_v0.02',\n",
    "                   method_spectrum:str='log_mel',\n",
    "                   test_ratio:float=0.15,\n",
    "                   val_ratio:float=0.05,\n",
    "                   batch_size:int=64,\n",
    "                   shuffle_buffer_size:int=1000,\n",
    "                   shuffle:bool=True,\n",
    "                   seed:int=42,\n",
    "                   verbose:int=1):\n",
    "    \"\"\"\n",
    "    Get the data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the data.\n",
    "    method_spectrum : str\n",
    "        Method to compute the spectrum.\n",
    "    test_ratio : float\n",
    "        Ratio of the data to be used as test set.\n",
    "    val_ratio : float\n",
    "        Ratio of the data to be used as validation set.\n",
    "    batch_size : int\n",
    "        Batch size.\n",
    "    shuffle_buffer_size : int\n",
    "        Shuffle buffer size.\n",
    "    shuffle : bool\n",
    "        Whether to shuffle the data.\n",
    "    seed : int\n",
    "        Seed for the random number generator.\n",
    "    verbose : int\n",
    "        Verbosity level.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    train : tf.data.Dataset\n",
    "        Training dataset.\n",
    "    test : tf.data.Dataset\n",
    "        Test dataset.\n",
    "    val : tf.data.Dataset\n",
    "        Validation dataset.\n",
    "    commands : list\n",
    "        List of commands.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the files.\n",
    "    data = DataLoader(\n",
    "        path=path\n",
    "    )\n",
    "    \n",
    "    commands = data.get_commands()\n",
    "    filenames = data.get_filenames()\n",
    "    train_files, test_files, val_files = data.split_data(\n",
    "        filenames=filenames,\n",
    "        test_ratio=test_ratio,\n",
    "        val_ratio=val_ratio,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    ds = DatasetBuilder(\n",
    "        commands=commands,\n",
    "        train_filenames=train_files,\n",
    "        test_filenames=test_files,\n",
    "        val_filenames=val_files,\n",
    "        batch_size=batch_size,\n",
    "        buffer_size=shuffle_buffer_size,\n",
    "        method=method_spectrum\n",
    "    )\n",
    "    \n",
    "    train, test, val = ds.preprocess_dataset_spectrogram()\n",
    "    \n",
    "    return train, test, val, commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val, commands = input_pipeline(\n",
    "    path='DATA/speech_commands_v0.02',\n",
    "    method_spectrum='log_mel',\n",
    "    test_ratio=0.15,\n",
    "    val_ratio=0.05,\n",
    "    batch_size=64,\n",
    "    shuffle_buffer_size=1000,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 15:03:30.822180: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "from models import CNNTradFPool3\n",
    "\n",
    "model = CNNTradFPool3(\n",
    "    train_ds = train,\n",
    "    test_ds = test,\n",
    "    val_ds = val,\n",
    "    commands = commands,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zatta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
