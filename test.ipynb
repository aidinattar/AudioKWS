{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataLoader, DataVisualizer, DatasetBuilder\n",
    "#from models import *\n",
    "import tensorflow as tf\n",
    "from utils.input import *\n",
    "\n",
    "def input_pipeline(path:str='DATA/speech_commands_v0.02',\n",
    "                   method_spectrum:str='log_mel',\n",
    "                   test_ratio:float=0.15,\n",
    "                   val_ratio:float=0.05,\n",
    "                   batch_size:int=64,\n",
    "                   shuffle_buffer_size:int=1000,\n",
    "                   shuffle:bool=True,\n",
    "                   seed:int=42,\n",
    "                   verbose:int=1):\n",
    "    \"\"\"\n",
    "    Get the data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the data.\n",
    "    method_spectrum : str\n",
    "        Method to compute the spectrum.\n",
    "    test_ratio : float\n",
    "        Ratio of the data to be used as test set.\n",
    "    val_ratio : float\n",
    "        Ratio of the data to be used as validation set.\n",
    "    batch_size : int\n",
    "        Batch size.\n",
    "    shuffle_buffer_size : int\n",
    "        Shuffle buffer size.\n",
    "    shuffle : bool\n",
    "        Whether to shuffle the data.\n",
    "    seed : int\n",
    "        Seed for the random number generator.\n",
    "    verbose : int\n",
    "        Verbosity level.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    train : tf.data.Dataset\n",
    "        Training dataset.\n",
    "    test : tf.data.Dataset\n",
    "        Test dataset.\n",
    "    val : tf.data.Dataset\n",
    "        Validation dataset.\n",
    "    commands : list\n",
    "        List of commands.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the files.\n",
    "    data = DataLoader(\n",
    "        path=path\n",
    "    )\n",
    "    \n",
    "    commands = data.get_commands()\n",
    "    filenames = data.get_filenames()\n",
    "    train_files, test_files, val_files = data.split_data(\n",
    "        filenames=filenames,\n",
    "        test_ratio=test_ratio,\n",
    "        val_ratio=val_ratio,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    ds = DatasetBuilder(\n",
    "        commands=commands,\n",
    "        train_filenames=train_files,\n",
    "        test_filenames=test_files,\n",
    "        val_filenames=val_files,\n",
    "        batch_size=batch_size,\n",
    "        buffer_size=shuffle_buffer_size,\n",
    "        method=method_spectrum\n",
    "    )\n",
    "    \n",
    "    train, test, val = ds.preprocess_dataset_spectrogram()\n",
    "    \n",
    "    return train, test, val, commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zatta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
